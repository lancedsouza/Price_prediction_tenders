{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e79ee5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\wishes lawrence\\anaconda3\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\wishes lawrence\\anaconda3\\lib\\site-packages (from pytesseract) (22.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\wishes lawrence\\anaconda3\\lib\\site-packages (from pytesseract) (9.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22dca071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to Excel successfully!\n"
     ]
    },
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <input type=\"text\" class=\"form-control datepicker hasDatepicker\" id=\"from_date_contract_search1\" value=\"03-01-2025\" name=\"from_date1\" required=\"\" readonly=\"readonly\"> is not clickable at point (319, 517). Other element would receive the click: <figure class=\"fig-img-logo gemmy-icon\" id=\"gemmyIcon\">...</figure>\n  (Session info: chrome=131.0.6778.265)\nStacktrace:\n\tGetHandleVerifier [0x00007FF726D880D5+2992373]\n\t(No symbol) [0x00007FF726A1BFD0]\n\t(No symbol) [0x00007FF7268B590A]\n\t(No symbol) [0x00007FF726910F2E]\n\t(No symbol) [0x00007FF72690E9CC]\n\t(No symbol) [0x00007FF72690BBA6]\n\t(No symbol) [0x00007FF72690AB01]\n\t(No symbol) [0x00007FF7268FCD40]\n\t(No symbol) [0x00007FF72692F36A]\n\t(No symbol) [0x00007FF7268FC596]\n\t(No symbol) [0x00007FF72692F580]\n\t(No symbol) [0x00007FF72694F584]\n\t(No symbol) [0x00007FF72692F113]\n\t(No symbol) [0x00007FF7268FA918]\n\t(No symbol) [0x00007FF7268FBA81]\n\tGetHandleVerifier [0x00007FF726DE6A2D+3379789]\n\tGetHandleVerifier [0x00007FF726DFC32D+3468109]\n\tGetHandleVerifier [0x00007FF726DF0043+3418211]\n\tGetHandleVerifier [0x00007FF726B7C78B+847787]\n\t(No symbol) [0x00007FF726A2757F]\n\t(No symbol) [0x00007FF726A22FC4]\n\t(No symbol) [0x00007FF726A2315D]\n\t(No symbol) [0x00007FF726A12979]\n\tBaseThreadInitThunk [0x00007FFDA99F257D+29]\n\tRtlUserThreadStart [0x00007FFDAB10AF08+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 43\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Handling Contract Date From\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Click on the input field to activate the calendar\u001b[39;00m\n\u001b[0;32m     42\u001b[0m date_input \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mID, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom_date_contract_search1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mdate_input\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Selecting the month (assuming you want to select January)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m year_dropdown \u001b[38;5;241m=\u001b[39m Select(driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mselect.ui-datepicker-year\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:94\u001b[0m, in \u001b[0;36mWebElement.click\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclick\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;124;03m\"\"\"Clicks the element.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCLICK_ELEMENT\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py:395\u001b[0m, in \u001b[0;36mWebElement._execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    393\u001b[0m     params \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    394\u001b[0m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:384\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    382\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 384\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    230\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <input type=\"text\" class=\"form-control datepicker hasDatepicker\" id=\"from_date_contract_search1\" value=\"03-01-2025\" name=\"from_date1\" required=\"\" readonly=\"readonly\"> is not clickable at point (319, 517). Other element would receive the click: <figure class=\"fig-img-logo gemmy-icon\" id=\"gemmyIcon\">...</figure>\n  (Session info: chrome=131.0.6778.265)\nStacktrace:\n\tGetHandleVerifier [0x00007FF726D880D5+2992373]\n\t(No symbol) [0x00007FF726A1BFD0]\n\t(No symbol) [0x00007FF7268B590A]\n\t(No symbol) [0x00007FF726910F2E]\n\t(No symbol) [0x00007FF72690E9CC]\n\t(No symbol) [0x00007FF72690BBA6]\n\t(No symbol) [0x00007FF72690AB01]\n\t(No symbol) [0x00007FF7268FCD40]\n\t(No symbol) [0x00007FF72692F36A]\n\t(No symbol) [0x00007FF7268FC596]\n\t(No symbol) [0x00007FF72692F580]\n\t(No symbol) [0x00007FF72694F584]\n\t(No symbol) [0x00007FF72692F113]\n\t(No symbol) [0x00007FF7268FA918]\n\t(No symbol) [0x00007FF7268FBA81]\n\tGetHandleVerifier [0x00007FF726DE6A2D+3379789]\n\tGetHandleVerifier [0x00007FF726DFC32D+3468109]\n\tGetHandleVerifier [0x00007FF726DF0043+3418211]\n\tGetHandleVerifier [0x00007FF726B7C78B+847787]\n\t(No symbol) [0x00007FF726A2757F]\n\t(No symbol) [0x00007FF726A22FC4]\n\t(No symbol) [0x00007FF726A2315D]\n\t(No symbol) [0x00007FF726A12979]\n\tBaseThreadInitThunk [0x00007FFDA99F257D+29]\n\tRtlUserThreadStart [0x00007FFDAB10AF08+40]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import time\n",
    "import io\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import pandas as pd\n",
    "\n",
    "# Function to solve CAPTCHA\n",
    "def solve_captcha(image_base64):\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    captcha_solution = pytesseract.image_to_string(image)\n",
    "    return captcha_solution.strip()\n",
    "\n",
    "# Start a Chrome WebDriver instance\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.maximize_window()\n",
    "\n",
    "try:\n",
    "    # Navigate to the target website\n",
    "    website = 'https://gem.gov.in/view_contracts'\n",
    "    driver.get(website)\n",
    "\n",
    "    # Handling drop down in the Category option\n",
    "    products_name = \"Cardiac Troponin T TEST KIT\"  # Replace with actual category\n",
    "    dropdown_category = Select(driver.find_element(By.ID, 'buyer_category'))\n",
    "    dropdown_category.select_by_visible_text('Cardiac Troponin T TEST KIT')\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Handling Contract Date From\n",
    "    # Click on the input field to activate the calendar\n",
    "    date_input = driver.find_element(By.ID, 'from_date_contract_search1')\n",
    "    date_input.click()\n",
    "\n",
    "    # Selecting the month (assuming you want to select January)\n",
    "\n",
    "    year_dropdown = Select(driver.find_element(By.CSS_SELECTOR, 'select.ui-datepicker-year'))\n",
    "    year_dropdown.select_by_visible_text('2024')\n",
    "\n",
    "    month_dropdown = Select(driver.find_element(By.CSS_SELECTOR, 'select.ui-datepicker-month'))\n",
    "    month_dropdown.select_by_visible_text('Sept')\n",
    "    # Click on the date (assuming you want to select the 1st of January)\n",
    "    date_element = driver.find_element(By.XPATH, '//a[text()=\"1\"]')\n",
    "    date_element.click()\n",
    "    \n",
    "    # Handling CAPTCHA\n",
    "    time.sleep(3)\n",
    "    captcha_image = driver.find_element(By.ID, 'captchaimg1').get_attribute('src').split(\",\")[1]\n",
    "    captcha_solution = solve_captcha(captcha_image)\n",
    "    captcha_input = driver.find_element(By.ID, 'captcha_code1')\n",
    "    captcha_input.send_keys(captcha_solution)\n",
    "\n",
    "    time.sleep(5)\n",
    "#     # Submit the form (adjust the form submission part as per your requirement)\n",
    "    submit_button = driver.find_element(By.ID, 'searchlocation1')  # Adjust this to the actual submit button's ID\n",
    "    submit_button.click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Data extraction lists\n",
    "    contract_number = []\n",
    "    organization_type = []\n",
    "    Ministry = []\n",
    "    Department = []\n",
    "    Organization_name = []\n",
    "    office_zone = []\n",
    "    Buyer_Designation = []\n",
    "    buying_mode = []\n",
    "    contract_date = []\n",
    "    Total = []\n",
    "    products = []\n",
    "    brands = []\n",
    "    models = []\n",
    "    Quantities = []\n",
    "    Prices = []\n",
    "\n",
    "    # Get the initial height of the page\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # Scroll down to the bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(10)  # Adjust the sleep time as needed\n",
    "\n",
    "        # Wait to load page\n",
    "        #\n",
    "        time.sleep(10)  # You can adjust this value as needed\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "        time.sleep(5)  # Adjust the sleep time as needed\n",
    "        \n",
    "\n",
    "    # Extracting all containers\n",
    "    all_containers = driver.find_elements(By.ID, 'pagi_content')\n",
    "\n",
    "    # Extracting info from each container\n",
    "    for container in all_containers:\n",
    "        try:\n",
    "            contract_no = container.find_elements(By.CLASS_NAME, 'ajxtag_order_number')\n",
    "            for contract in contract_no:\n",
    "                contract_number.append(contract.text)\n",
    "        except NoSuchElementException:\n",
    "            contract_number.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            org_type = container.find_elements(By.XPATH, '//p/strong[text()=\"Organization Type: \"]/following-sibling::span[@class=\"ajxtag_buyer_dept_org\"]')\n",
    "            for org in org_type:\n",
    "                organization_type.append(org.text)\n",
    "        except NoSuchElementException:\n",
    "            organization_type.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            ministry = container.find_elements(By.XPATH, '//p/strong[text()=\"Ministry: \"]/following-sibling::span[@class=\"ajxtag_buying_mode\"]')\n",
    "            for ele in ministry:\n",
    "                Ministry.append(ele.text)\n",
    "        except NoSuchElementException:\n",
    "            Ministry.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            department = container.find_elements(By.XPATH, '//p/strong[text()=\"Department: \"]/following-sibling::span[@class=\"ajxtag_buying_mode\"]')\n",
    "            for dept in department:\n",
    "                Department.append(dept.text)\n",
    "        except NoSuchElementException:\n",
    "            Department.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            org_name = container.find_elements(By.XPATH, '//p/strong[text()=\"Organization Name: \"]/following-sibling::span[@class=\"ajxtag_buyer_dept_org\"]')\n",
    "            for org in org_name:\n",
    "                Organization_name.append(org.text)\n",
    "        except NoSuchElementException:\n",
    "            Organization_name.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            off_zone = container.find_elements(By.XPATH, '//p/strong[text()=\"Office Zone: \"]/following-sibling::span[@class=\"ajxtag_buying_mode\"]')\n",
    "            for zone in off_zone:\n",
    "                office_zone.append(zone.text)\n",
    "        except NoSuchElementException:\n",
    "            office_zone.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            buyer_designation_element = container.find_elements(By.XPATH, '//p/strong[text()=\"Buyer Designation: \"]/following-sibling::span[@class=\"ajxtag_buyer_dept_org\"]')\n",
    "            for designation in buyer_designation_element:\n",
    "                Buyer_Designation.append(designation.text)\n",
    "        except NoSuchElementException:\n",
    "            Buyer_Designation.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            buy_mode = container.find_elements(By.XPATH, '//p/strong[text()=\"Buying Mode: \"]/following-sibling::span[@class=\"ajxtag_buying_mode\"]')\n",
    "            for mode in buy_mode:\n",
    "                buying_mode.append(mode.text)\n",
    "        except NoSuchElementException:\n",
    "            buying_mode.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            contr_date = container.find_elements(By.XPATH, '//p/strong[text()=\"Contract Date: \"]/following-sibling::span[@class=\"ajxtag_contract_date\"]')\n",
    "            for date in contr_date:\n",
    "                contract_date.append(date.text)\n",
    "        except NoSuchElementException:\n",
    "            contract_date.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            total = container.find_elements(By.XPATH, '//p/strong[text()=\"Total: \"]/following-sibling::span[@class=\"ajxtag_totalvalue\"]')\n",
    "            for value in total:\n",
    "                Total.append(value.text)\n",
    "        except NoSuchElementException:\n",
    "            Total.append(\"N/A\")\n",
    "            \n",
    "        container1=container.find_elements(By.XPATH,'/html/body/section[2]/div[1]/div/div[1]/div[2]/div[3]/div[7]/table')\n",
    "        if len(container1)>0:\n",
    "            \n",
    "            for i in container1:\n",
    "            \n",
    "        \n",
    "                try:\n",
    "                    prods = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[1]')\n",
    "                    for prod in prods:\n",
    "                        products.append(prod.text)\n",
    "                except NoSuchElementException:\n",
    "                    products.append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    brand_ = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[2]')\n",
    "                    for brand in brand_:\n",
    "                        brands.append(brand.text)\n",
    "                except NoSuchElementException:\n",
    "                    brands.append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    model_ = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[3]')\n",
    "                    for model in model_:\n",
    "                        models.append(model.text)\n",
    "                except NoSuchElementException:\n",
    "                    models.append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    quantity_ = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[4]')\n",
    "                    for quantity in quantity_:\n",
    "                        Quantities.append(quantity.text)\n",
    "                except NoSuchElementException:\n",
    "                    Quantities.append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    price_ = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[5]')\n",
    "                    for price in price_:\n",
    "                        Prices.append(price.text)\n",
    "                except NoSuchElementException:\n",
    "                    Prices.append(\"N/A\")\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'contract_number': contract_number,\n",
    "        'organization_type': organization_type,\n",
    "        'Ministry': Ministry,\n",
    "        'Department': Department,\n",
    "        'Organization_name': Organization_name,\n",
    "        'office_zone': office_zone,\n",
    "        'Buyer_Designation': Buyer_Designation,\n",
    "        'buying_mode': buying_mode,\n",
    "        'contract_date': contract_date,\n",
    "        'Total': Total,\n",
    "        'products': products,\n",
    "        'brands': brands,\n",
    "        'models': models,\n",
    "        'Quantities': Quantities,\n",
    "        'Prices': Prices\n",
    "    })\n",
    "\n",
    "    # Save the data to the 'data' directory\n",
    "#     data_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'data')\n",
    "#     if not os.path.exists(data_dir):\n",
    "#         os.makedirs(data_dir)\n",
    "\n",
    "  # Export DataFrame to Excel\n",
    "    df.to_excel(\"Cardiac_Marker_TroponinT_Sept_to_Nov2024.xlsx\", index=False)\n",
    "finally:\n",
    "    print(\"Data exported to Excel successfully!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bf2e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3f06b15",
   "metadata": {},
   "source": [
    "\n",
    "New Scraper which scrapes all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d54bb15",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 223\u001b[0m\n\u001b[0;32m    216\u001b[0m                 Prices\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mN/A\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# Create DataFrame\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontract_number\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontract_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43morganization_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43morganization_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    226\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mMinistry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mMinistry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDepartment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mDepartment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOrganization_name\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mOrganization_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moffice_zone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moffice_zone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBuyer_Designation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mBuyer_Designation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbuying_mode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuying_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontract_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontract_date\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTotal\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mTotal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mproducts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mproducts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbrands\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrands\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    236\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuantities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mQuantities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPrices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mPrices\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;66;03m# Export DataFrame to Excel\u001b[39;00m\n\u001b[0;32m    242\u001b[0m df\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCardiac_Marker_TroponinT_Sep_Nov_2024.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:664\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    658\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    659\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    660\u001b[0m     )\n\u001b[0;32m    662\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    663\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 664\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    666\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    671\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import time\n",
    "import io\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import pandas as pd\n",
    "\n",
    "# Function to solve CAPTCHA\n",
    "def solve_captcha(image_base64):\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    captcha_solution = pytesseract.image_to_string(image)\n",
    "    return captcha_solution.strip()\n",
    "\n",
    "# Start a Chrome WebDriver instance\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Set up WebDriverWait\n",
    "wait = WebDriverWait(driver, 20)  # 20 seconds timeout\n",
    "\n",
    "try:\n",
    "    # Navigate to the target website\n",
    "    website = 'https://gem.gov.in/view_contracts'\n",
    "    driver.get(website)\n",
    "\n",
    "    # Handling drop down in the Category option\n",
    "    products_name = \"Cardiac Troponin T TEST KIT\"  # Replace with actual category\n",
    "    dropdown_category = Select(wait.until(EC.presence_of_element_located((By.ID, 'buyer_category'))))\n",
    "    dropdown_category.select_by_visible_text(products_name)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Handling Contract Date From\n",
    "    # Click on the input field to activate the calendar\n",
    "    date_input = wait.until(EC.element_to_be_clickable((By.ID, 'from_date_contract_search1')))\n",
    "    date_input.click()\n",
    "\n",
    "    # Selecting the month and year\n",
    "    year_dropdown = Select(wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'select.ui-datepicker-year'))))\n",
    "    year_dropdown.select_by_visible_text('2024')\n",
    "\n",
    "    month_dropdown = Select(wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'select.ui-datepicker-month'))))\n",
    "    month_dropdown.select_by_visible_text('Sep')\n",
    "\n",
    "    # Click on the date (assuming you want to select the 1st of January)\n",
    "    date_element = wait.until(EC.element_to_be_clickable((By.XPATH, '//a[text()=\"1\"]')))\n",
    "    date_element.click()\n",
    "    \n",
    "    # Handling CAPTCHA\n",
    "    time.sleep(3)\n",
    "    captcha_image = driver.find_element(By.ID, 'captchaimg1').get_attribute('src').split(\",\")[1]\n",
    "    captcha_solution = solve_captcha(captcha_image)\n",
    "    captcha_input = wait.until(EC.presence_of_element_located((By.ID, 'captcha_code1')))\n",
    "    captcha_input.send_keys(captcha_solution)\n",
    "\n",
    "    # Submit the form\n",
    "    submit_button = wait.until(EC.element_to_be_clickable((By.ID, 'searchlocation1')))\n",
    "    submit_button.click()\n",
    "\n",
    "    # Wait for the results to load\n",
    "    wait.until(EC.presence_of_element_located((By.ID, 'pagi_content')))\n",
    "    \n",
    "    # Data extraction lists\n",
    "    contract_number = []\n",
    "    organization_type = []\n",
    "    Ministry = []\n",
    "    Department = []\n",
    "    Organization_name = []\n",
    "    office_zone = []\n",
    "    Buyer_Designation = []\n",
    "    buying_mode = []\n",
    "    contract_date = []\n",
    "    Total = []\n",
    "    products = []\n",
    "    brands = []\n",
    "    models = []\n",
    "    Quantities = []\n",
    "    Prices = []\n",
    "\n",
    "    # Scroll to load all content\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)  # Adjust time if needed\n",
    "        \n",
    "        # Wait until new content is loaded\n",
    "        try:\n",
    "            wait.until(lambda d: driver.execute_script(\"return document.body.scrollHeight\") > last_height)\n",
    "        except TimeoutException:\n",
    "            break  # Exit loop if no new content is loaded\n",
    "\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        time.sleep(2)  # Adjust time if needed\n",
    "\n",
    "    # Extracting all containers\n",
    "    all_containers = driver.find_elements(By.ID, 'pagi_content')\n",
    "\n",
    "    # Extracting info from each container\n",
    "    for container in all_containers:\n",
    "        try:\n",
    "            contract_no = container.find_elements(By.CLASS_NAME, 'ajxtag_order_number')\n",
    "            for contract in contract_no:\n",
    "                contract_number.append(contract.text)\n",
    "        except NoSuchElementException:\n",
    "            contract_number.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            org_type = container.find_elements(By.XPATH, '//p/strong[text()=\"Organization Type: \"]/following-sibling::span[@class=\"ajxtag_buyer_dept_org\"]')\n",
    "            for org in org_type:\n",
    "                organization_type.append(org.text)\n",
    "        except NoSuchElementException:\n",
    "            organization_type.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            ministry = container.find_elements(By.XPATH, '//p/strong[text()=\"Ministry: \"]/following-sibling::span[@class=\"ajxtag_buying_mode\"]')\n",
    "            for ele in ministry:\n",
    "                Ministry.append(ele.text)\n",
    "        except NoSuchElementException:\n",
    "            Ministry.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            department = container.find_elements(By.XPATH, '//p/strong[text()=\"Department: \"]/following-sibling::span[@class=\"ajxtag_buying_mode\"]')\n",
    "            for dept in department:\n",
    "                Department.append(dept.text)\n",
    "        except NoSuchElementException:\n",
    "            Department.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            org_name = container.find_elements(By.XPATH, '//p/strong[text()=\"Organization Name: \"]/following-sibling::span[@class=\"ajxtag_buyer_dept_org\"]')\n",
    "            for org in org_name:\n",
    "                Organization_name.append(org.text)\n",
    "        except NoSuchElementException:\n",
    "            Organization_name.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            off_zone = container.find_elements(By.XPATH, '//p/strong[text()=\"Office Zone: \"]/following-sibling::span[@class=\"ajxtag_buying_mode\"]')\n",
    "            for zone in off_zone:\n",
    "                office_zone.append(zone.text)\n",
    "        except NoSuchElementException:\n",
    "            office_zone.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            buyer_designation_element = container.find_elements(By.XPATH, '//p/strong[text()=\"Buyer Designation: \"]/following-sibling::span[@class=\"ajxtag_buyer_dept_org\"]')\n",
    "            for designation in buyer_designation_element:\n",
    "                Buyer_Designation.append(designation.text)\n",
    "        except NoSuchElementException:\n",
    "            Buyer_Designation.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            buy_mode = container.find_elements(By.XPATH, '//p/strong[text()=\"Buying Mode: \"]/following-sibling::span[@class=\"ajxtag_buying_mode\"]')\n",
    "            for mode in buy_mode:\n",
    "                buying_mode.append(mode.text)\n",
    "        except NoSuchElementException:\n",
    "            buying_mode.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            contr_date = container.find_elements(By.XPATH, '//p/strong[text()=\"Contract Date: \"]/following-sibling::span[@class=\"ajxtag_contract_date\"]')\n",
    "            for date in contr_date:\n",
    "                contract_date.append(date.text)\n",
    "        except NoSuchElementException:\n",
    "            contract_date.append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            total = container.find_elements(By.XPATH, '//p/strong[text()=\"Total: \"]/following-sibling::span[@class=\"ajxtag_totalvalue\"]')\n",
    "            for value in total:\n",
    "                Total.append(value.text)\n",
    "        except NoSuchElementException:\n",
    "            Total.append(\"N/A\")\n",
    "            \n",
    "        container1 = container.find_elements(By.XPATH, '/html/body/section[2]/div[1]/div/div[1]/div[2]/div[3]/div[7]/table')\n",
    "        if len(container1) > 0:\n",
    "            for i in container1:\n",
    "                try:\n",
    "                    prods = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[1]')\n",
    "                    for prod in prods:\n",
    "                        products.append(prod.text)\n",
    "                except NoSuchElementException:\n",
    "                    products.append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    brand_ = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[2]')\n",
    "                    for brand in brand_:\n",
    "                        brands.append(brand.text)\n",
    "                except NoSuchElementException:\n",
    "                    brands.append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    model_ = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[3]')\n",
    "                    for model in model_:\n",
    "                        models.append(model.text)\n",
    "                except NoSuchElementException:\n",
    "                    models.append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    quantity_ = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[4]')\n",
    "                    for quantity in quantity_:\n",
    "                        Quantities.append(quantity.text)\n",
    "                except NoSuchElementException:\n",
    "                    Quantities.append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    price_ = container.find_elements(By.XPATH, './/table/tbody/tr[2]/td[5]')\n",
    "                    for price in price_:\n",
    "                        Prices.append(price.text)\n",
    "                except NoSuchElementException:\n",
    "                    Prices.append(\"N/A\")\n",
    "                    \n",
    "                    \n",
    "        \n",
    "\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'contract_number': contract_number,\n",
    "        'organization_type': organization_type,\n",
    "        'Ministry': Ministry,\n",
    "        'Department': Department,\n",
    "        'Organization_name': Organization_name,\n",
    "        'office_zone': office_zone,\n",
    "        'Buyer_Designation': Buyer_Designation,\n",
    "        'buying_mode': buying_mode,\n",
    "        'contract_date': contract_date,\n",
    "        'Total': Total,\n",
    "        'products': products,\n",
    "        'brands': brands,\n",
    "        'models': models,\n",
    "        'Quantities': Quantities,\n",
    "        'Prices': Prices\n",
    "    })\n",
    "\n",
    "    # Export DataFrame to Excel\n",
    "    df.to_excel(\"Cardiac_Marker_TroponinT_Sep_Nov_2024.xlsx\", index=False)\n",
    "    print(\"Data exported to Excel successfully!\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3028c0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling Array length mismatch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dcc5c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to Excel successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import base64\n",
    "import time\n",
    "import io\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "import pandas as pd\n",
    "\n",
    "# Function to solve CAPTCHA\n",
    "def solve_captcha(image_base64):\n",
    "    image_data = base64.b64decode(image_base64)\n",
    "    image = Image.open(io.BytesIO(image_data))\n",
    "    captcha_solution = pytesseract.image_to_string(image)\n",
    "    return captcha_solution.strip()\n",
    "\n",
    "# Start a Chrome WebDriver instance\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--disable-notifications\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "driver.maximize_window()\n",
    "\n",
    "# Set up WebDriverWait\n",
    "wait = WebDriverWait(driver, 20)  # 20 seconds timeout\n",
    "\n",
    "try:\n",
    "    # Navigate to the target website\n",
    "    website = 'https://gem.gov.in/view_contracts'\n",
    "    driver.get(website)\n",
    "\n",
    "    # Handling dropdown in the Category option\n",
    "    products_name = \"Cardiac Troponin T TEST KIT\"  # Replace with actual category\n",
    "    dropdown_category = Select(wait.until(EC.presence_of_element_located((By.ID, 'buyer_category'))))\n",
    "    dropdown_category.select_by_visible_text(products_name)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Handling Contract Date From\n",
    "    date_input = wait.until(EC.element_to_be_clickable((By.ID, 'from_date_contract_search1')))\n",
    "    date_input.click()\n",
    "\n",
    "    # Selecting the month and year\n",
    "    year_dropdown = Select(wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'select.ui-datepicker-year'))))\n",
    "    year_dropdown.select_by_visible_text('2024')\n",
    "\n",
    "    month_dropdown = Select(wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, 'select.ui-datepicker-month'))))\n",
    "    month_dropdown.select_by_visible_text('Sep')\n",
    "\n",
    "    # Click on the date (assuming you want to select the 1st of September)\n",
    "    date_element = wait.until(EC.element_to_be_clickable((By.XPATH, '//a[text()=\"1\"]')))\n",
    "    date_element.click()\n",
    "\n",
    "    # Handling CAPTCHA\n",
    "    time.sleep(3)\n",
    "    captcha_image = driver.find_element(By.ID, 'captchaimg1').get_attribute('src').split(\",\")[1]\n",
    "    captcha_solution = solve_captcha(captcha_image)\n",
    "    captcha_input = wait.until(EC.presence_of_element_located((By.ID, 'captcha_code1')))\n",
    "    captcha_input.send_keys(captcha_solution)\n",
    "\n",
    "    # Submit the form\n",
    "    submit_button = wait.until(EC.element_to_be_clickable((By.ID, 'searchlocation1')))\n",
    "    submit_button.click()\n",
    "\n",
    "    # Wait for the results to load\n",
    "    wait.until(EC.presence_of_element_located((By.ID, 'pagi_content')))\n",
    "\n",
    "    # Data extraction lists\n",
    "    data = {\n",
    "        \"contract_number\": [],\n",
    "        \"organization_type\": [],\n",
    "        \"Ministry\": [],\n",
    "        \"Department\": [],\n",
    "        \"Organization_name\": [],\n",
    "        \"office_zone\": [],\n",
    "        \"Buyer_Designation\": [],\n",
    "        \"buying_mode\": [],\n",
    "        \"contract_date\": [],\n",
    "        \"Total\": [],\n",
    "        \"products\": [],\n",
    "        \"brands\": [],\n",
    "        \"models\": [],\n",
    "        \"Quantities\": [],\n",
    "        \"Prices\": []\n",
    "    }\n",
    "\n",
    "    # Scroll to load all content\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Extracting all containers\n",
    "    all_containers = driver.find_elements(By.ID, 'pagi_content')\n",
    "\n",
    "    # Extracting info from each container\n",
    "    for container in all_containers:\n",
    "        try:\n",
    "            data[\"contract_number\"].append(container.find_element(By.CLASS_NAME, 'ajxtag_order_number').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"contract_number\"].append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            data[\"organization_type\"].append(container.find_element(By.XPATH, './/strong[text()=\"Organization Type: \"]/following-sibling::span').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"organization_type\"].append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            data[\"Ministry\"].append(container.find_element(By.XPATH, './/strong[text()=\"Ministry: \"]/following-sibling::span').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"Ministry\"].append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            data[\"Department\"].append(container.find_element(By.XPATH, './/strong[text()=\"Department: \"]/following-sibling::span').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"Department\"].append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            data[\"Organization_name\"].append(container.find_element(By.XPATH, './/strong[text()=\"Organization Name: \"]/following-sibling::span').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"Organization_name\"].append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            data[\"office_zone\"].append(container.find_element(By.XPATH, './/strong[text()=\"Office Zone: \"]/following-sibling::span').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"office_zone\"].append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            data[\"Buyer_Designation\"].append(container.find_element(By.XPATH, './/strong[text()=\"Buyer Designation: \"]/following-sibling::span').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"Buyer_Designation\"].append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            data[\"buying_mode\"].append(container.find_element(By.XPATH, './/strong[text()=\"Buying Mode: \"]/following-sibling::span').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"buying_mode\"].append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            data[\"contract_date\"].append(container.find_element(By.XPATH, './/strong[text()=\"Contract Date: \"]/following-sibling::span').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"contract_date\"].append(\"N/A\")\n",
    "\n",
    "        try:\n",
    "            data[\"Total\"].append(container.find_element(By.XPATH, './/strong[text()=\"Total: \"]/following-sibling::span').text)\n",
    "        except NoSuchElementException:\n",
    "            data[\"Total\"].append(\"N/A\")\n",
    "\n",
    "        product_table = container.find_elements(By.XPATH, './/table')\n",
    "        if product_table:\n",
    "            for row in product_table:\n",
    "                try:\n",
    "                    data[\"products\"].append(row.find_element(By.XPATH, './tbody/tr[2]/td[1]').text)\n",
    "                except NoSuchElementException:\n",
    "                    data[\"products\"].append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    data[\"brands\"].append(row.find_element(By.XPATH, './tbody/tr[2]/td[2]').text)\n",
    "                except NoSuchElementException:\n",
    "                    data[\"brands\"].append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    data[\"models\"].append(row.find_element(By.XPATH, './tbody/tr[2]/td[3]').text)\n",
    "                except NoSuchElementException:\n",
    "                    data[\"models\"].append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    data[\"Quantities\"].append(row.find_element(By.XPATH, './tbody/tr[2]/td[4]').text)\n",
    "                except NoSuchElementException:\n",
    "                    data[\"Quantities\"].append(\"N/A\")\n",
    "\n",
    "                try:\n",
    "                    data[\"Prices\"].append(row.find_element(By.XPATH, './tbody/tr[2]/td[5]').text)\n",
    "                except NoSuchElementException:\n",
    "                    data[\"Prices\"].append(\"N/A\")\n",
    "\n",
    "    # Ensure consistent length across all lists\n",
    "    max_length = max(len(v) for v in data.values())\n",
    "    for key in data.keys():\n",
    "        data[key].extend([\"N/A\"] * (max_length - len(data[key])))\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Export DataFrame to Excel\n",
    "    df.to_excel(\"Cardiac_Marker_TroponinT_Sep_Nov_2024.xlsx\", index=False)\n",
    "    print(\"Data exported to Excel successfully!\")\n",
    "\n",
    "finally:\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb147006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to Excel successfully!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90797f4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
