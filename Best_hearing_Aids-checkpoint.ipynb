{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c0a0422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca04e48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading contents of the web page\n",
    "url = \"https://www.ncoa.org/adviser/hearing-aids/best-hearing-aids/\"\n",
    "data = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "11f2d76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating BeautifulSoup object\n",
    "soup = BeautifulSoup(data, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "85ab7970",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after 'for' statement on line 20 (3580363116.py, line 21)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[88], line 21\u001b[1;36m\u001b[0m\n\u001b[1;33m    header.append(td[i].text)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after 'for' statement on line 20\n"
     ]
    }
   ],
   "source": [
    "\n",
    "table=soup.find('table')\n",
    "\n",
    "# Find all 'th' elements\n",
    "th_elements =table.find_all('th')\n",
    "headers=[]\n",
    "for header in headers:\n",
    "    globals()[header] = []  # Create a list for each header name\n",
    "\n",
    "# Loop through each 'th' element\n",
    "for th_element in th_elements:\n",
    "    # Check if 'data-brand-id' attribute exists\n",
    "    if 'data-brand-id' in th_element.attrs:\n",
    "        brand_name = th_element['data-brand-id']\n",
    "        headers.append(brand_name)\n",
    "\n",
    "table_row=table.find_all('tr')\n",
    "\n",
    "for tr in table_row:\n",
    "    td=tr.find_all('td')\n",
    "    for header in headers:\n",
    "    header.append(td[i].text)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ed8f0704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReSound\n",
      "ReSound\n",
      "ReSound\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# Creating BeautifulSoup object\n",
    "# Downloading contents of the web page\n",
    "url = \"https://www.ncoa.org/adviser/hearing-aids/best-hearing-aids/\"\n",
    "data = requests.get(url).text\n",
    "\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table = soup.find('table')\n",
    "\n",
    "# Find all 'th' elements and extract headers\n",
    "th_elements = table.find_all('th')\n",
    "headers = []\n",
    "\n",
    "# Create empty lists dynamically for each header\n",
    "for th_element in th_elements:\n",
    "    if 'data-brand-id' in th_element.attrs:\n",
    "        brand_name = th_element['data-brand-id']\n",
    "        headers.append(brand_name)\n",
    "        globals()[brand_name] = []  # Dynamically create lists for each header\n",
    "\n",
    "# Find all rows in the table (excluding the header row)\n",
    "table_rows = table.find_all('tr')[1:]  # Skip the first row (header)\n",
    "\n",
    "# Loop through each table row\n",
    "for tr in table_rows:\n",
    "    td_elements = tr.find_all('td')\n",
    "    # Loop through headers and corresponding td values\n",
    "    for i, header in enumerate(headers):\n",
    "        for td in td_elements:\n",
    "            globals()[header].append(td_elements[i].text)\n",
    "    print(header)\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "       \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "adc2ba31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jabra Enhance: ['Rechargeable', 'Yes', '1 year (Jabra Enhance Plus) 3 years (Enhance Select 50R, 300, and 500)', 'Yes']\n",
      "Audien: ['Rechargeable', 'No', '1 year', 'No']\n",
      "Eargo: ['Rechargeable', 'Yesfor adjustments only, no streaming', '1–2 years', 'Yes']\n",
      "MDHearing: ['Rechargeable', 'Yesfor adjustments only, no streaming', '1 year', 'Yes']\n",
      "hear.com: ['Rechargeable', 'Yes', '1–3 years', 'Yes']\n",
      "Lexie: ['Rechargeable and disposable', 'Yesadjustments only, no streaming; iPhone call streaming through B2 model only', '1 year', 'Yes']\n",
      "Phonak: ['Rechargeable', 'Yes', 'Depends on retailer', 'Depends on retailer']\n",
      "Audicus: ['Rechargeable with disposable options', 'Yes (except the Mini)', '2 years', 'Yes']\n",
      "Signia: ['Disposable', 'No', '2 years', 'Depends on retailer']\n",
      "ReSound: ['Rechargeable and disposable', 'Yes', 'Depends on retailer', 'Depends on retailer']\n",
      "                                       Jabra Enhance        Audien  \\\n",
      "0                                       Rechargeable  Rechargeable   \n",
      "1                                                Yes            No   \n",
      "2  1 year (Jabra Enhance Plus) 3 years (Enhance S...        1 year   \n",
      "3                                                Yes            No   \n",
      "\n",
      "                                   Eargo  \\\n",
      "0                           Rechargeable   \n",
      "1  Yesfor adjustments only, no streaming   \n",
      "2                              1–2 years   \n",
      "3                                    Yes   \n",
      "\n",
      "                               MDHearing      hear.com  \\\n",
      "0                           Rechargeable  Rechargeable   \n",
      "1  Yesfor adjustments only, no streaming           Yes   \n",
      "2                                 1 year     1–3 years   \n",
      "3                                    Yes           Yes   \n",
      "\n",
      "                                               Lexie               Phonak  \\\n",
      "0                        Rechargeable and disposable         Rechargeable   \n",
      "1  Yesadjustments only, no streaming; iPhone call...                  Yes   \n",
      "2                                             1 year  Depends on retailer   \n",
      "3                                                Yes  Depends on retailer   \n",
      "\n",
      "                                Audicus               Signia  \\\n",
      "0  Rechargeable with disposable options           Disposable   \n",
      "1                 Yes (except the Mini)                   No   \n",
      "2                               2 years              2 years   \n",
      "3                                   Yes  Depends on retailer   \n",
      "\n",
      "                       ReSound  \n",
      "0  Rechargeable and disposable  \n",
      "1                          Yes  \n",
      "2          Depends on retailer  \n",
      "3          Depends on retailer  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "# Downloading contents of the web page\n",
    "url = \"https://www.ncoa.org/adviser/hearing-aids/best-hearing-aids/\"\n",
    "data = requests.get(url).text\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table = soup.find('table')\n",
    "\n",
    "# Find all 'th' elements and extract headers\n",
    "th_elements = table.find_all('th')\n",
    "headers = []\n",
    "\n",
    "# Create empty lists dynamically for each header\n",
    "for th_element in th_elements:\n",
    "    if 'data-brand-id' in th_element.attrs:\n",
    "        brand_name = th_element['data-brand-id']\n",
    "        headers.append(brand_name)\n",
    "        globals()[brand_name] = []  # Dynamically create lists for each header\n",
    "\n",
    "# Find all rows in the table (excluding the header row)\n",
    "table_rows = table.find_all('tr')  # Skip the first row (header)\n",
    "\n",
    "# Loop through each table row and append values to the corresponding header lists\n",
    "for tr in table_rows:\n",
    "    td_elements = tr.find_all('td')[1:]\n",
    "    # Loop through headers and corresponding td values\n",
    "    for i, header in enumerate(headers):\n",
    "        if i < len(td_elements):  # Ensure we don't go out of index range\n",
    "            globals()[header].append(td_elements[i].text)  # Append td text to the corresponding header list\n",
    "\n",
    "# Now print the dynamically created lists to verify\n",
    "for header in headers:\n",
    "    print(f'{header}: {globals()[header]}')\n",
    "    # Create a dictionary to hold data for DataFrame\n",
    "data_dict = {header: globals()[header] for header in headers}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel(\"Best_hearing_aids_2024.xlsx\", index=False)  # Add .xlsx extension and set index to False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "22d2d512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "header1: ['Row 1 Col 1', 'Row 2 Col 1']\n",
      "header2: ['Row 1 Col 2', 'Row 2 Col 2']\n",
      "header3: ['Row 1 Col 3', 'Row 2 Col 3']\n",
      "       header1      header2      header3\n",
      "0  Row 1 Col 1  Row 1 Col 2  Row 1 Col 3\n",
      "1  Row 2 Col 1  Row 2 Col 2  Row 2 Col 3\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# Sample HTML data (replace this with your actual HTML data)\n",
    "\n",
    "\n",
    "# Parse the HTML\n",
    "soup = BeautifulSoup(data, 'html.parser')\n",
    "\n",
    "# Find the table element\n",
    "table = soup.find('table')\n",
    "\n",
    "# Find all 'th' elements and extract headers\n",
    "th_elements = table.find_all('th')\n",
    "headers = []\n",
    "\n",
    "# Create empty lists dynamically for each header\n",
    "for th_element in th_elements:\n",
    "    if 'data-brand-id' in th_element.attrs:\n",
    "        brand_name = th_element['data-brand-id']\n",
    "        headers.append(brand_name)\n",
    "        globals()[brand_name] = []  # Dynamically create lists for each header\n",
    "\n",
    "# Find all rows in the table (including the header row)\n",
    "table_rows = table.find_all('tr')  # No need to skip header\n",
    "\n",
    "# Loop through each table row and append values to the corresponding header lists\n",
    "for tr in table_rows[1:]:  # Start from the second row\n",
    "    td_elements = tr.find_all('td')\n",
    "    # Loop through headers and corresponding td values\n",
    "    for i, header in enumerate(headers):\n",
    "        if i < len(td_elements):  # Ensure we don't go out of index range\n",
    "            globals()[header].append(td_elements[i].text)  # Append td text to the corresponding header list\n",
    "\n",
    "# Now print the dynamically created lists to verify\n",
    "for header in headers:\n",
    "    print(f'{header}: {globals()[header]}')\n",
    "\n",
    "# Create a dictionary to hold data for DataFrame\n",
    "data_dict = {header: globals()[header] for header in headers}\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Save the DataFrame to an Excel file\n",
    "df.to_excel(\"Best_hearing_aids_2024.xlsx\", index=False)  # Add .xlsx extension and set index to False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c94def",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
