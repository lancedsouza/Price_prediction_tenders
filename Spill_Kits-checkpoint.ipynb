{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18270962-1053-44eb-87ad-b783d2e07020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final Code"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c18ede1e-3e5d-4c59-afd8-b00df9b6373d",
   "metadata": {},
   "source": [
    "Company name xpath\n",
    "//li[contains(@class,\"sid_df sid_jcc fww sid_aic mCnmGrp flx1 mAse\")]//a/span\n",
    "Comapny url xpath\n",
    "//li[contains(@class,\"sid_df sid_jcc fww sid_aic mCnmGrp flx1 mAse\")]//a\n",
    "Productname and price are in this list\n",
    "<li class=\"mListPrc\"><span class=\"mListNme p10b0 mDib clr111 fs14 dsif\" data-click=\"^Prod0Name\"><a href=\"https://www.indiamart.com/proddetail/4l-laboratory-spill-containment-tray-2853780039133.html\" class=\"elps prodNameClamp\" target=\"_blank\"><h3>4L Laboratory Spill Containment Tray</h3></a>\n",
    "                                </span><p id=\"1prcenq\" class=\"NP-1 mPrc mDb\"><span class=\"prc cp tcur\">₹ 2,300/<span class=\"quan\">Piece</span></span></p><span class=\"desc des_p \"><div class=\"isqlist\" id=\"isq1\"><div class=\"fs14 color tabledesc mt10\"><table><tbody><tr><td class=\"tdwdt\"><div class=\"dsf\"><span>Model No</span></div></td><td class=\"tdwdt1 color6\"><div class=\"dsf\"><span> IC-1818</span></div></td></tr><tr><td class=\"tdwdt\"><div class=\"dsf\"><span>Usage/Application</span></div></td><td class=\"tdwdt1 color6\"><div class=\"dsf\"><span> Chemical Laboratory</span></div></td></tr><tr><td class=\"tdwdt\"><div class=\"dsf\"><span>Material</span></div></td><td class=\"tdwdt1 color6\"><div class=\"dsf\"><span> LLDPE</span></div></td></tr><tr style=\"display: none;\"><td class=\"tdwdt\"><div class=\"dsf\"><span>Shape</span></div></td><td class=\"tdwdt1 color6\"><div class=\"dsf\"><span> Square</span></div></td></tr><tr style=\"display: none;\"><td class=\"tdwdt\"><div class=\"dsf\"><span>Size/Dimension</span></div></td><td class=\"tdwdt1 color6\"><div class=\"dsf\"><span> (OD) L450 X W450 X H 40 mm</span></div></td></tr><tr style=\"display: none;\"><td class=\"tdwdt\"><div class=\"dsf\"><span>Tray Shape</span></div></td><td class=\"tdwdt1 color6\"><div class=\"dsf\"><span> Square</span></div></td></tr></tbody></table></div></div></span>            </li>\n",
    "Product_name xpath\n",
    "//li[contains(@class,\"mListPrc\")]/span/a/h3\n",
    "element for price\n",
    "<span class=\"prc cp tcur\">₹ 11,500/<span class=\"quan\">Piece</span></span>\n",
    "xpath for price\n",
    "//span[contains(@ class,\"prc cp tcur\")]\n",
    "element for company name\n",
    "<span class=\"elps\">Baroda Polyform Pvt Ltd</span>\n",
    "//h2[contains(@class,\"cname ph10\")]/a/span\n",
    "Address is in this list\n",
    "<li class=\"sid_df sid_jcc fww sid_aic mCnmGrp flx1 mAse\" id=\"compnameAndAdd_1\"><div style=\"flex-direction:column;margin-bottom: 10px;\" class=\"dsif\"><h2 class=\"lcname ph10\" data-click=\"^CompanyName\"><a href=\"https://www.plasticpallet.co.in/\" target=\"_blank\" class=\"mCnme\"><span class=\"elps\">Swift Technoplast Private Limited</span></a></h2>\n",
    "            <!-- <p class=\"mPr sid_df sid_jcc mH17\"> -->\n",
    "            <span style=\"margin-top:2px;\" class=\"sm clg mDb flx1 to-txt-align\" data-rlocation=\"Midc\"><div class=\"to-txt-pos to-txt-ex-div\"><span style=\"text-align:left;\" class=\"elps\">Midc, Navi Mumbai, Dist. Thane </span><span class=\"to-txt tc lft1\" id=\"citytt1\"><span class=\"mDib mToTxt\">\n",
    "                 B-116 &amp; B-117, Punit Industrail Estate, TTC Industrial Area,Midc, Turbhe, Midc, Navi Mumbai - 400705, Dist. Thane, Maharashtra</span></span></div></span>\n",
    "\n",
    "            <p class=\"sid_df sid_aic ph10\" style=\"flex-wrap:wrap;gap:5px;\">\n",
    "                \n",
    "                            <span class=\"sid_aic\" style=\"display:flex;gap: 5px;\">\n",
    "                    <i style=\"background-position: 1px 3px;width:14px;\" class=\"gstv_icn\"></i>\n",
    "                    <span class=\"gst-ver\">GST</span>\n",
    "                </span>\n",
    "                \n",
    "                            \n",
    "                \n",
    "                \n",
    "                                      <span>|</span>\n",
    "                      <span style=\"cursor:pointer;\" data-click=\"^TrustSEAL\" data-val=\"plasticpallet\" class=\"sid_df sid_aic tsclick\"><i style=\"background-position: 3px -81px;background-size:42px;\" class=\"ts_icn\"></i>TrustSeal Verified</span>                    <span style=\"padding-right:3px;\">|</span>\n",
    "                    <span class=\"sid_df sid_aic\">\n",
    "                    <i style=\"background-position: -40px -63px;background-size: 54px;width:18px;\" class=\"vexp_icn\"></i> \n",
    "                   Verified Exporter<span class=\"exptr-tl-tip mpa off\">IndiaMART Verified Exporter</span></span>               <!-- </p> -->\n",
    "               \n",
    "            </p>\n",
    "\n",
    "           <div class=\"sid_df sid_aic\" style=\"padding:0 10px;display:inline-grid;justify-content:left;\">\n",
    "\n",
    "               <div class=\"sprt sid_df sid_aic\" id=\"sellerrating_1\" onclick=\"recordOutboundLink(1,'SellerRating','Clicked_Grid',0,0)\"><div style=\"    margin-left: -2px;\" class=\"sRt pdinb fs16 pd_tal pr\"><div class=\"flsRt pd_l0 abslt\" style=\"width:82%; display: flex; gap: 0;\"><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starFilled\"></use></svg><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starFilled\"></use></svg><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starFilled\"></use></svg><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starFilled\"></use></svg><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starFilled\"></use></svg></div><div class=\"emsRt\" style=\"display: flex; gap: 0;\"><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starOutline\"></use></svg><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starOutline\"></use></svg><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starOutline\"></use></svg><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starOutline\"></use></svg><svg width=\"12\" height=\"11\" style=\"flex-shrink: 0;\"><use xlink:href=\"#starOutline\"></use></svg></div></div><span style=\"margin-left:5px;\" class=\"bo color fs12\">4.1</span> <span style=\"margin-left: 3px;\" class=\"color\"> (118)</span></div>            <span id=\"pnsno_1\" class=\"pns-rr pdt5\" style=\"padding-left:0px;display:flex;\"><svg style=\"padding-right:4px;\" width=\"12\" height=\"11\" class=\"wh13 mr5\">\n",
    "                <use xlink:href=\"#phoneIcon\"></use>\n",
    "                </svg>69% Response Rate </span>            </div>\n",
    "            </div></li>\n",
    "address xpath\n",
    "//div[contains(@class,\"to-txt-pos to-txt-ex-div\")]/span\n",
    "Xpath full address\n",
    "//span[contains(@class,\"mDib mToTxt\")]\n",
    "xpath rating\n",
    "//*[@id=\"sellerrating_1\"]/span[1]\n",
    "num of ratings\n",
    "//*[@id=\"sellerrating_1\"]/span[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f02e8d9-18c3-43ba-a579-0bb4aebc4bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 132 products and 56 companies\n",
      "Data saved to indiamart_products_complete.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Configure Chrome\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "def scrape_indiamart():\n",
    "    driver.get(\"https://dir.indiamart.com/impcat/spill-containment-pallets.html\")\n",
    "    time.sleep(random.uniform(3, 5))\n",
    "    \n",
    "    product_data = []\n",
    "    \n",
    "    # Scroll to load all products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    # Extract all product and company containers\n",
    "    products = driver.find_elements(By.XPATH, '//li[contains(@class,\"mListPrc\")]')\n",
    "    companies = driver.find_elements(By.XPATH, '//li[contains(@class,\"sid_df sid_jcc fww sid_aic mCnmGrp flx1 mAse\")]')\n",
    "\n",
    "    print(f\"Found {len(products)} products and {len(companies)} companies\")\n",
    "\n",
    "    for index in range(min(len(products), len(companies))):\n",
    "        product = products[index]\n",
    "        company = companies[index]\n",
    "        data = {}\n",
    "\n",
    "        # --- Product Info ---\n",
    "        try:\n",
    "            data['Product Name'] = product.find_element(By.XPATH, './/h3').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Product Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Price'] = product.find_element(By.XPATH, './/span[contains(@class,\"prc cp tcur\")]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Price'] = 'N/A'\n",
    "\n",
    "        # --- Company Info ---\n",
    "        try:\n",
    "            data['Company Name'] = company.find_element(By.XPATH, './/h2[contains(@class,\"cname\")]/a/span').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Company Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company URL'] = company.find_element(By.XPATH, './/h2[contains(@class,\"cname\")]/a').get_attribute('href')\n",
    "        except NoSuchElementException:\n",
    "            data['Company URL'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Address'] = company.find_element(By.XPATH, './/div[contains(@class,\"to-txt-pos\")]/span').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Address'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_element = company.find_element(By.XPATH, './/span[contains(@class,\"bo color fs12\")]')\n",
    "            data['Rating'] = rating_element.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Rating'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_count_element = company.find_element(By.XPATH, './/span[2][contains(@class,\"color\")]')\n",
    "            data['Number of Ratings'] = rating_count_element.text.strip('()')\n",
    "        except NoSuchElementException:\n",
    "            data['Number of Ratings'] = 'N/A'\n",
    "\n",
    "        product_data.append(data)\n",
    "    \n",
    "    # Save to Excel\n",
    "    df = pd.DataFrame(product_data)\n",
    "    df.to_excel('indiamart_products_complete.xlsx', index=False)\n",
    "    print(\"Data saved to indiamart_products_complete.xlsx\")\n",
    "\n",
    "    driver.quit()\n",
    "\n",
    "scrape_indiamart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851fbd04-2fd0-421d-bac6-ff16eedeefe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 products\n",
      "✅ Data saved to 'indiamart_drum_pallets.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "\n",
    "# Launch WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "def scrape_indiamart():\n",
    "    driver.get(\"https://dir.indiamart.com/search.mp?ss=drum+pallets&prdsrc=1&v=4&mcatid=&catid=&var=B&tags=res:RC3|ktp:N0|stype:attr=1|mtp:S|wc:2|qr_nm:gd|cs:14278|com-cf:nl|ptrs:na|mc:26923|cat:803|qry_typ:P|lang:en|flavl:0|rtn:0-0-1-0-0-9-0|qrd:250526|mrd:250520|prdt:250527|msf:hs\")\n",
    "    time.sleep(random.uniform(3, 5))\n",
    "\n",
    "    product_data = []\n",
    "\n",
    "    # Scroll to load more products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(2, 3))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Find all product cards\n",
    "    products = driver.find_elements(By.XPATH, '//div[contains(@class,\"listingCardContainer\")]/div[contains(@class,\"card\") and @data-datatype=\"product\"]')\n",
    "    print(f\"Found {len(products)} products\")\n",
    "\n",
    "    for product in products:\n",
    "        data = {}\n",
    "\n",
    "        try:\n",
    "            data['Product Name'] = product.find_element(By.XPATH, './/a[contains(@class,\"cardlinks\")]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Product Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Price'] = product.find_element(By.XPATH, './/p[contains(@class,\"price\")]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Price'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company Name'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Company Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company URL'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').get_attribute('href')\n",
    "        except NoSuchElementException:\n",
    "            data['Company URL'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Address'] = product.find_element(By.XPATH, './/div[contains(@class,\"newLocationUi\")]//p').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Address'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(@class,\"bo\")]')\n",
    "            data['Rating'] = rating_element.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Rating'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_count_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(text(), \"(\")]')\n",
    "            data['Number of Ratings'] = rating_count_element.text.strip(\"()\")\n",
    "        except NoSuchElementException:\n",
    "            data['Number of Ratings'] = 'N/A'\n",
    "\n",
    "        product_data.append(data)\n",
    "\n",
    "    # Save data to Excel\n",
    "    df = pd.DataFrame(product_data)\n",
    "    df.to_excel('indiamart_drum_pallets.xlsx', index=False)\n",
    "    print(\"✅ Data saved to 'indiamart_drum_pallets.xlsx'\")\n",
    "\n",
    "    # Quit the driver\n",
    "    driver.quit()\n",
    "\n",
    "# Run the scraper\n",
    "scrape_indiamart()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4b18b04-2604-4487-a1f0-c2e292a06414",
   "metadata": {},
   "source": [
    "https://dir.indiamart.com/search.mp?ss=Plastic+pallets&prdsrc=1&v=4&mcatid=&catid=&var=C&tags=res:RC4|ktp:N0|stype:attr=1|mtp:G|grpfl:14|wc:2|qr_nm:gd|cs:15238|com-cf:nl|ptrs:na|mc:253|cat:803|qry_typ:P|lang:en|flavl:0-2|rtn:0-0-0-1-2-7-0|qrd:250527|mrd:250516|prdt:250528|msf:hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6509f353-36ca-4c7b-9781-7a2332a867d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 products\n",
      "✅ Data saved to 'indiamart_plastic_pallets.xlsx'\n"
     ]
    }
   ],
   "source": [
    "#Plastic Pellets\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "\n",
    "# Launch WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "def scrape_indiamart():\n",
    "    driver.get(\"https://dir.indiamart.com/search.mp?ss=Plastic+pallets&prdsrc=1&v=4&mcatid=&catid=&var=C&tags=res:RC4|ktp:N0|stype:attr=1|mtp:G|grpfl:14|wc:2|qr_nm:gd|cs:15238|com-cf:nl|ptrs:na|mc:253|cat:803|qry_typ:P|lang:en|flavl:0-2|rtn:0-0-0-1-2-7-0|qrd:250527|mrd:250516|prdt:250528|msf:hs\")\n",
    "    time.sleep(random.uniform(3, 5))\n",
    "\n",
    "    product_data = []\n",
    "\n",
    "    # Scroll to load more products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(2, 3))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Find all product cards\n",
    "    products = driver.find_elements(By.XPATH, '//div[contains(@class,\"listingCardContainer\")]/div[contains(@class,\"card\") and @data-datatype=\"product\"]')\n",
    "    print(f\"Found {len(products)} products\")\n",
    "\n",
    "    for product in products:\n",
    "        data = {}\n",
    "\n",
    "        try:\n",
    "            data['Product Name'] = product.find_element(By.XPATH, './/a[contains(@class,\"cardlinks\")]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Product Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Price'] = product.find_element(By.XPATH, './/p[contains(@class,\"price\")]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Price'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company Name'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Company Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company URL'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').get_attribute('href')\n",
    "        except NoSuchElementException:\n",
    "            data['Company URL'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Address'] = product.find_element(By.XPATH, './/div[contains(@class,\"newLocationUi\")]//p').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Address'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(@class,\"bo\")]')\n",
    "            data['Rating'] = rating_element.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Rating'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_count_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(text(), \"(\")]')\n",
    "            data['Number of Ratings'] = rating_count_element.text.strip(\"()\")\n",
    "        except NoSuchElementException:\n",
    "            data['Number of Ratings'] = 'N/A'\n",
    "\n",
    "        product_data.append(data)\n",
    "\n",
    "    # Save data to Excel\n",
    "    df = pd.DataFrame(product_data)\n",
    "    df.to_excel('indiamart_plastic_pallets.xlsx', index=False)\n",
    "    print(\"✅ Data saved to 'indiamart_plastic_pallets.xlsx'\")\n",
    "\n",
    "    # Quit the driver\n",
    "    driver.quit()\n",
    "\n",
    "# Run the scraper\n",
    "scrape_indiamart()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bfd424a-6fb6-40e1-a488-52a000d6813e",
   "metadata": {},
   "source": [
    "HDPE Pallet URL\n",
    "https://dir.indiamart.com/search.mp?ss=hdpe+pallet&prdsrc=1&v=4&mcatid=253&catid=803&var=C&src=as-context%7Ckwd%3Dhdpe+%7Cpos%3D1%7Ccat%3D803%7Cmcat%3D253%7Ckwd_len%3D5%7Ckwd_cnt%3D2&tags=res:RC3|ktp:N0|stype:attr=1|mtp:S|wc:2|qr_nm:gd|cs:14163|com-cf:nl|ptrs:na|mc:85925|cat:803|qry_typ:P|lang:en|flavl:0|rtn:0-0-1-0-3-6-0|qrd:250526|mrd:250519|prdt:250528|msf:hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0389b0de-20b9-40e5-add1-df6584307771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 products\n",
      "✅ Data saved to 'indiamart_HDPE_pallets.xlsx'\n"
     ]
    }
   ],
   "source": [
    "#HDPE Molded                                                                                                                                                                                                                                                                                                     \n",
    "#Plastic Pellets\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "\n",
    "# Launch WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "def scrape_indiamart():\n",
    "    driver.get(\"https://dir.indiamart.com/search.mp?ss=hdpe+pallet&prdsrc=1&v=4&mcatid=253&catid=803&var=C&src=as-context%7Ckwd%3Dhdpe+%7Cpos%3D1%7Ccat%3D803%7Cmcat%3D253%7Ckwd_len%3D5%7Ckwd_cnt%3D2&tags=res:RC3|ktp:N0|stype:attr=1|mtp:S|wc:2|qr_nm:gd|cs:14163|com-cf:nl|ptrs:na|mc:85925|cat:803|qry_typ:P|lang:en|flavl:0|rtn:0-0-1-0-3-6-0|qrd:250526|mrd:250519|prdt:250528|msf:hs\")\n",
    "    time.sleep(random.uniform(3, 5))\n",
    "\n",
    "    product_data = []\n",
    "\n",
    "    # Scroll to load more products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(2, 3))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Find all product cards\n",
    "    products = driver.find_elements(By.XPATH, '//div[contains(@class,\"listingCardContainer\")]/div[contains(@class,\"card\") and @data-datatype=\"product\"]')\n",
    "    print(f\"Found {len(products)} products\")\n",
    "\n",
    "    for product in products:\n",
    "        data = {}\n",
    "\n",
    "        try:\n",
    "            data['Product Name'] = product.find_element(By.XPATH, './/a[contains(@class,\"cardlinks\")]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Product Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Price'] = product.find_element(By.XPATH, './/div[contains(@class,\"cardbody cardPadding\")]/div//p').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Price'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company Name'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Company Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company URL'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').get_attribute('href')\n",
    "        except NoSuchElementException:\n",
    "            data['Company URL'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Address'] = product.find_element(By.XPATH, './/div[contains(@class,\"newLocationUi\")]//p').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Address'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(@class,\"bo\")]')\n",
    "            data['Rating'] = rating_element.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Rating'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_count_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(text(), \"(\")]')\n",
    "            data['Number of Ratings'] = rating_count_element.text.strip(\"()\")\n",
    "        except NoSuchElementException:\n",
    "            data['Number of Ratings'] = 'N/A'\n",
    "\n",
    "        product_data.append(data)\n",
    "\n",
    "    # Save data to Excel\n",
    "    df = pd.DataFrame(product_data)\n",
    "    df.to_excel('indiamart_HDPE_pallets.xlsx', index=False)\n",
    "    print(\"✅ Data saved to 'indiamart_HDPE_pallets.xlsx'\")\n",
    "\n",
    "    # Quit the driver\n",
    "    driver.quit()\n",
    "\n",
    "# Run the scraper\n",
    "scrape_indiamart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef14ce4-e7de-411b-a6c2-7b14835e3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://dir.indiamart.com/search.mp?ss=roto+molded+plastic+pallets&prdsrc=1&v=4&mcatid=85925&catid=803&var=B&src=as-context%7Ckwd%3Droto+%7Cpos%3D1%7Ccat%3D803%7Cmcat%3D85925%7Ckwd_len%3D5%7Ckwd_cnt%3D2&tags=res:RC3|ktp:N0|stype:attr=1|mtp:S|wc:4|qr_nm:gd|cs:15887|com-cf:nl|ptrs:na|mc:155519|cat:803|qry_typ:P|lang:en|flavl:0-2|rtn:0-0-0-0-2-8-0|qrd:250526|mrd:250516|prdt:250529|msf:hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67e6c28d-d6ca-4d67-b83c-77cd284718de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 products\n",
      "✅ Data saved to 'indiamart_Rotomolded_pallets.xlsx'\n"
     ]
    }
   ],
   "source": [
    "#RotoMolded pallets\n",
    "#Plastic Pellets\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "\n",
    "# Launch WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "def scrape_indiamart():\n",
    "    driver.get(\"https://dir.indiamart.com/search.mp?ss=roto+molded+plastic+pallets&prdsrc=1&v=4&mcatid=85925&catid=803&var=B&src=as-context%7Ckwd%3Droto+%7Cpos%3D1%7Ccat%3D803%7Cmcat%3D85925%7Ckwd_len%3D5%7Ckwd_cnt%3D2&tags=res:RC3|ktp:N0|stype:attr=1|mtp:S|wc:4|qr_nm:gd|cs:15887|com-cf:nl|ptrs:na|mc:155519|cat:803|qry_typ:P|lang:en|flavl:0-2|rtn:0-0-0-0-2-8-0|qrd:250526|mrd:250516|prdt:250529|msf:hs\")\n",
    "    time.sleep(random.uniform(3, 5))\n",
    "\n",
    "    product_data = []\n",
    "\n",
    "    # Scroll to load more products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(2, 3))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Find all product cards\n",
    "    products = driver.find_elements(By.XPATH, '//div[contains(@class,\"listingCardContainer\")]/div[contains(@class,\"card\") and @data-datatype=\"product\"]')\n",
    "    print(f\"Found {len(products)} products\")\n",
    "\n",
    "    for product in products:\n",
    "        data = {}\n",
    "\n",
    "        try:\n",
    "            data['Product Name'] = product.find_element(By.XPATH, './/a[contains(@class,\"cardlinks\")]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Product Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Price'] = product.find_element(By.XPATH, './/div[contains(@class,\"cardbody cardPadding\")]/div//p').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Price'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company Name'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Company Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company URL'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').get_attribute('href')\n",
    "        except NoSuchElementException:\n",
    "            data['Company URL'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Address'] = product.find_element(By.XPATH, './/div[contains(@class,\"newLocationUi\")]//p').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Address'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(@class,\"bo\")]')\n",
    "            data['Rating'] = rating_element.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Rating'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_count_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(text(), \"(\")]')\n",
    "            data['Number of Ratings'] = rating_count_element.text.strip(\"()\")\n",
    "        except NoSuchElementException:\n",
    "            data['Number of Ratings'] = 'N/A'\n",
    "\n",
    "        product_data.append(data)\n",
    "\n",
    "    # Save data to Excel\n",
    "    df = pd.DataFrame(product_data)\n",
    "    df.to_excel('indiamart_Rotomolded_pallets.xlsx', index=False)\n",
    "    print(\"✅ Data saved to 'indiamart_Rotomolded_pallets.xlsx'\")\n",
    "\n",
    "    # Quit the driver\n",
    "    driver.quit()\n",
    "\n",
    "# Run the scraper\n",
    "scrape_indiamart()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbd0807-ce43-4fe8-9356-d43eb8a8ae94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spill Containment trays\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--start-maximized\")\n",
    "\n",
    "# Launch WebDriver\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "def scrape_indiamart():\n",
    "    driver.get(\"https://dir.indiamart.com/search.mp?ss=spill+containment+tray&src=as-popular%7Ckwd%3Dspill+containment+%7Cpos%3D5%7Ccat%3D-2%7Cmcat%3D-2%7Ckwd_len%3D18%7Ckwd_cnt%3D3&prdsrc=1&v=4&mcatid=&catid=&cq=&tags=res:RC3|ktp:N0|stype:attr=1|mtp:S|wc:3|qr_nm:gd|cs:15301|com-cf:nl|ptrs:na|mc:37496|cat:803|qry_typ:P|lang:en|flavl:0|rtn:0-0-2-0-2-6-0|qrd:250530|mrd:250522|prdt:250603|msf:hs\")\n",
    "    time.sleep(random.uniform(3, 5))\n",
    "\n",
    "    product_data = []\n",
    "\n",
    "    # Scroll to load more products\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(random.uniform(2, 3))\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "    # Find all product cards\n",
    "    products = driver.find_elements(By.XPATH, '//div[contains(@class,\"listingCardContainer\")]/div[contains(@class,\"card\") and @data-datatype=\"product\"]')\n",
    "    print(f\"Found {len(products)} products\")\n",
    "\n",
    "    for product in products:\n",
    "        data = {}\n",
    "\n",
    "        try:\n",
    "            data['Product Name'] = product.find_element(By.XPATH, './/a[contains(@class,\"cardlinks\")]').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Product Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Price'] = product.find_element(By.XPATH, './/div[contains(@class,\"cardbody cardPadding\")]/div//p').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Price'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company Name'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Company Name'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Company URL'] = product.find_element(By.XPATH, './/div[contains(@class,\"companyname\")]/a').get_attribute('href')\n",
    "        except NoSuchElementException:\n",
    "            data['Company URL'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            data['Address'] = product.find_element(By.XPATH, './/div[contains(@class,\"newLocationUi\")]//p').text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Address'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(@class,\"bo\")]')\n",
    "            data['Rating'] = rating_element.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            data['Rating'] = 'N/A'\n",
    "\n",
    "        try:\n",
    "            rating_count_element = product.find_element(By.XPATH, './/div[@id[contains(., \"sellerrating\")]]//span[contains(text(), \"(\")]')\n",
    "            data['Number of Ratings'] = rating_count_element.text.strip(\"()\")\n",
    "        except NoSuchElementException:\n",
    "            data['Number of Ratings'] = 'N/A'\n",
    "\n",
    "        product_data.append(data)\n",
    "\n",
    "    # Save data to Excel\n",
    "    df = pd.DataFrame(product_data)\n",
    "    df.to_excel('indiamart_SpillContainment_trays.xlsx', index=False)\n",
    "    print(\"✅ Data saved to 'indiamart_SpillContainment_trays.xlsx'\")\n",
    "\n",
    "    # Quit the driver\n",
    "    driver.quit()\n",
    "\n",
    "# Run the scraper\n",
    "scrape_indiamart()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
